{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import codecs\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import markdown\n",
    "\n",
    "# with open('Manovich.md', 'r') as f: text = f.read()\n",
    "# texts = text.split(\"\\n# \")[2:] # Split and remove the first two elements\n",
    "\n",
    "with open('PAP.md', 'r') as f: text = f.read()\n",
    "texts = text.split(\"\\n\") # Split and remove the first two elements\n",
    "\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 "
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "import textacy.tm\n",
    "import textacy.preprocessing\n",
    "\n",
    "# en = textacy.load_spacy_lang(\"en_core_web_sm\", disable=(\"parser\",))\n",
    "en = textacy.load_spacy_lang(\"en_core_web_lg\", disable=(\"parser\",))\n",
    "# en = textacy.load_spacy_lang(\"en_core_web_trf\", disable=(\"parser\",))\n",
    "\n",
    "docs = []\n",
    "titles = [] # List of titles\n",
    "\n",
    "for index, text in enumerate(texts):\n",
    "    titles.append(text.split('\\n\\n')[0])\n",
    "    docs.append(textacy.make_spacy_doc(text, lang=en))\n",
    "    print(index, end=' ')\n",
    "    # print(doc._.preview)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<56x466 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1003 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "stopwords = {'pap'}\n",
    "\n",
    "lemmas = []\n",
    "\n",
    "ngs = partial(textacy.extract.ngrams, n=[1], include_pos={'NOUN'})\n",
    "# ngs = partial(textacy.extract.ngrams, n=[1, 2], include_pos={'ADJ', 'NOUN'})\n",
    "# ngs = partial(textacy.extract.ngrams, n=[1], include_pos={\"NOUN\"})\n",
    "# ents = partial(textacy.extract.entities, include_types={\"PERSON\", \"ORG\", \"GPE\", \"LOC\"})\n",
    "\n",
    "for doc in docs:\n",
    "    # extraction = textacy.extract.keyterms.textrank(doc, normalize='lemma')\n",
    "    extraction = textacy.extract.terms(doc, ngs=ngs)\n",
    "    # extraction = textacy.extract.basics.words(doc, filter_stops=True, filter_nums=True)\n",
    "    lemmatization = textacy.extract.terms_to_strings(extraction, by=\"lemma\")\n",
    "    \n",
    "     # Remove strings containing stopwords\n",
    "    lemmatization = [l for l in lemmatization if not any(stopword in l for stopword in stopwords)]\n",
    "    lemmatization = [l for l in lemmatization if not '||||' in l]\n",
    "    \n",
    "    for index, l in enumerate(lemmatization):\n",
    "        if 'datum' in l : lemmatization[index] = l.replace('datum', 'data')\n",
    "        if 'medium' in l : lemmatization[index] = l.replace('medium', 'media')\n",
    "        \n",
    "    lemmas.append(list(lemmatization))\n",
    "\n",
    "# TF-IDF\n",
    "\n",
    "doc_term_matrix, dictionary = textacy.representations.build_doc_term_matrix(lemmas, tf_type=\"linear\", idf_type=\"smooth\")\n",
    "\n",
    "doc_term_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import umap\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "from pointgrid import align_points_to_grid\n",
    "\n",
    "reducer = umap.UMAP(random_state=2, n_components=2, n_neighbors=5, min_dist=0.01, metric='cosine')\n",
    "# reducer = umap.UMAP(random_state=2, n_components=2, n_neighbors=3, min_dist=0.01, metric='hellinger')\n",
    "\n",
    "embedding = reducer.fit_transform(doc_term_matrix)\n",
    "embedding = align_points_to_grid(embedding)\n",
    "# embedding = (embedding - np.min(embedding))/np.ptp(embedding) # Normalize 0:1\n",
    "embedding = np.multiply(embedding, 1000) # Multiply 100\n",
    "embedding = embedding.astype(int) # Int\n",
    "\n",
    "# Normalize image to between 0 and 255\n",
    "# embedding *= (255.0/image.max())\n",
    "\n",
    "x = embedding[:, 0]; y = embedding[:, 1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=50)\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.axis('equal')\n",
    "\n",
    "# for i, title in enumerate(titles):\n",
    "#     text = plt.annotate(title, (x[i], y[i]))\n",
    "#     text.set_fontsize(5)\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmas Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 lexical pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[475.0, 0.0, ['number', 'graph', 'spot']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while len(pairs) == 0:\n",
    "    i += .05\n",
    "    \n",
    "    for indexA, a in enumerate(embedding):\n",
    "        for indexB, b in enumerate(embedding):\n",
    "            if indexB > indexA:\n",
    "                distance = dist = math.sqrt((b[0] - a[0])**2 + (b[1] - a[1])**2)\n",
    "                if 0 < distance and distance < i:\n",
    "                    x = (b[0] + a[0]) / 2\n",
    "                    y = (b[1] + a[1]) / 2\n",
    "                    \n",
    "                    intersection = list(set(lemmas[indexA]) & set(lemmas[indexB]))\n",
    "\n",
    "                    wordfreq = []\n",
    "                    for lemma in intersection:\n",
    "                        wordfreq.append([lemma, lemmas[indexA].count(lemma) + lemmas[indexA].count(lemma)])\n",
    "                    \n",
    "                    wordfreq.sort(key=lambda x:x[1])\n",
    "                    wordfreq.reverse()\n",
    "\n",
    "                    pairs.append([x,y, [i[0] for i in wordfreq[:3]] ])\n",
    "\n",
    "\n",
    "print(len(pairs), 'lexical pairs')\n",
    "pairs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hdbscan\n",
    "\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=4, min_samples=3, cluster_selection_epsilon=.2)\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_method='leaf')\n",
    "# min_samples is to consier all the elements that owtherwide will be classified as noise\n",
    "# cluster_selection_epsilon extends clusters\n",
    "clusterer.fit(embedding)\n",
    "clusters = clusterer.labels_\n",
    "\n",
    "# Grouping by cluster\n",
    "\n",
    "values = set(clusters)\n",
    "if -1 in values: values.remove(-1)\n",
    "\n",
    "clusters = [[index for index, cluster in enumerate(clusters) if cluster==value] for value in values]\n",
    "\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(embedding.tolist(), codecs.open('../src/data/embedding.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "# json.dump(authors, codecs.open('../src/data/authors.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "json.dump(lemmas, codecs.open('../src/data/lemmas.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "json.dump(pairs, codecs.open('../src/data/pairs.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "# json.dump(topics, codecs.open('../src/data/topics.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "json.dump(clusters, codecs.open('../src/data/clusters.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 - 1 2 - 2 1 - 3 2 - 4 2 - "
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, get_single_color_func\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# from planar import Polygon # It's not working anymore\n",
    "\n",
    "from os import path\n",
    "import multidict as multidict\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "for index, cluster in enumerate(clusters):\n",
    "\n",
    "    # Preprocessing\n",
    "\n",
    "    scale = 3\n",
    "    \n",
    "    min_X = min([i[0] for i in embedding[cluster]]) * scale\n",
    "    max_X = max([i[0] for i in embedding[cluster]]) * scale\n",
    "    min_Y = min([i[1] for i in embedding[cluster]]) * scale\n",
    "    max_Y = max([i[1] for i in embedding[cluster]]) * scale\n",
    "\n",
    "    width = max_X - min_X; height = max_Y - min_Y\n",
    "    \n",
    "    points = list(map(lambda i: (i[0] * scale - min_X, i[1] * scale - min_Y), embedding[cluster]))\n",
    "\n",
    "    # Hull\n",
    "\n",
    "    hull = ConvexHull(points)\n",
    "\n",
    "    x_hull = np.append(hull.points[hull.vertices,0], hull.points[hull.vertices,0][0])\n",
    "    y_hull = np.append(hull.points[hull.vertices,1], hull.points[hull.vertices,1][0])\n",
    "    \n",
    "    # Interpolation\n",
    "    \n",
    "    dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "    interp_x, interp_y = interpolate.splev(interp_d, spline)    \n",
    "    interp_points = list(zip(interp_x, interp_y))\n",
    "\n",
    "    # Create mask\n",
    "\n",
    "    img = Image.new(mode = \"RGBA\", size = (width, height), color = (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # draw.polygon(points, fill=(0,0,0))\n",
    "    draw.polygon(interp_points, fill=(0,0,0))\n",
    "    mask = np.array(img)\n",
    "\n",
    "\n",
    "    # Collect text\n",
    "\n",
    "    text = []\n",
    "    for id in cluster:\n",
    "        text = text + lemmas[id]\n",
    "    text = ' '.join(map(str, text))\n",
    "    # text = text.replace('datum', 'data')\n",
    "    # text = text.replace('medium', 'media')\n",
    "\n",
    "    dictionary = multidict.MultiDict()\n",
    "    _dictionary = {}\n",
    "\n",
    "\n",
    "    # Frequency\n",
    "\n",
    "    for _word in text.split(\" \"):\n",
    "        val = _dictionary.get(_word, 0)\n",
    "        _dictionary[_word] = val + 1\n",
    "    for key in _dictionary:\n",
    "        dictionary.add(key, _dictionary[key])\n",
    "\n",
    "\n",
    "    # Wordcloud\n",
    "\n",
    "    max_words = math.ceil(len(dictionary)*.01)\n",
    "\n",
    "\n",
    "    wc = WordCloud(\n",
    "        mode = \"RGBA\",\n",
    "        color_func=lambda *args, **kwargs: (0, 0, 0),\n",
    "        font_path = path.join('Lato-Regular.ttf'),\n",
    "        mask=mask,\n",
    "        \n",
    "        normalize_plurals=False,\n",
    "        prefer_horizontal= 1,\n",
    "        \n",
    "        margin=40,\n",
    "\n",
    "        background_color=None,\n",
    "        # background_color='black',\n",
    "\n",
    "        # max_words=max_words,\n",
    "        \n",
    "        min_font_size= 10,\n",
    "        max_font_size= 100,\n",
    "        # collocation_threshold = 20,\n",
    "        relative_scaling = 0,\n",
    "    )\n",
    "\n",
    "    print(index, max_words, '-', end=' ')\n",
    "    \n",
    "    wc.generate_from_frequencies(dictionary) # generate word cloud\n",
    "    wc.to_file(path.join(\"../src/wordclouds/\" + f\"{index:02}\" + \".png\")) # store to file\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
