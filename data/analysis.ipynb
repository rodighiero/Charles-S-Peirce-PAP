{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import codecs\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import markdown\n",
    "\n",
    "# with open('Manovich.md', 'r') as f: text = f.read()\n",
    "# texts = text.split(\"\\n# \")[2:] # Split and remove the first two elements\n",
    "\n",
    "with open('PAP.md', 'r') as f: text = f.read()\n",
    "texts = text.split(\"\\n\") # Split and remove the first two elements\n",
    "\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 "
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "import textacy.tm\n",
    "import textacy.preprocessing\n",
    "\n",
    "# en = textacy.load_spacy_lang(\"en_core_web_sm\", disable=(\"parser\",))\n",
    "en = textacy.load_spacy_lang(\"en_core_web_lg\", disable=(\"parser\",))\n",
    "# en = textacy.load_spacy_lang(\"en_core_web_trf\", disable=(\"parser\",))\n",
    "\n",
    "docs = []\n",
    "titles = [] # List of titles\n",
    "\n",
    "for index, text in enumerate(texts):\n",
    "    titles.append(text.split('\\n\\n')[0])\n",
    "    docs.append(textacy.make_spacy_doc(text, lang=en))\n",
    "    print(index, end=' ')\n",
    "    # print(doc._.preview)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<56x466 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1003 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "stopwords = {'pap'}\n",
    "\n",
    "lemmas = []\n",
    "\n",
    "ngs = partial(textacy.extract.ngrams, n=[1], include_pos={'NOUN'})\n",
    "# ngs = partial(textacy.extract.ngrams, n=[1, 2], include_pos={'ADJ', 'NOUN'})\n",
    "# ngs = partial(textacy.extract.ngrams, n=[1], include_pos={\"NOUN\"})\n",
    "# ents = partial(textacy.extract.entities, include_types={\"PERSON\", \"ORG\", \"GPE\", \"LOC\"})\n",
    "\n",
    "for doc in docs:\n",
    "    # extraction = textacy.extract.keyterms.textrank(doc, normalize='lemma')\n",
    "    extraction = textacy.extract.terms(doc, ngs=ngs)\n",
    "    # extraction = textacy.extract.basics.words(doc, filter_stops=True, filter_nums=True)\n",
    "    lemmatization = textacy.extract.terms_to_strings(extraction, by=\"lemma\")\n",
    "    \n",
    "     # Remove strings containing stopwords\n",
    "    lemmatization = [l for l in lemmatization if not any(stopword in l for stopword in stopwords)]\n",
    "    lemmatization = [l for l in lemmatization if not '||||' in l]\n",
    "    \n",
    "    for index, l in enumerate(lemmatization):\n",
    "        if 'datum' in l : lemmatization[index] = l.replace('datum', 'data')\n",
    "        if 'medium' in l : lemmatization[index] = l.replace('medium', 'media')\n",
    "        \n",
    "    lemmas.append(list(lemmatization))\n",
    "\n",
    "# TF-IDF\n",
    "\n",
    "doc_term_matrix, dictionary = textacy.representations.build_doc_term_matrix(lemmas, tf_type=\"linear\", idf_type=\"smooth\")\n",
    "\n",
    "doc_term_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import umap\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "from pointgrid import align_points_to_grid\n",
    "\n",
    "reducer = umap.UMAP(random_state=2, n_components=2, n_neighbors=5, min_dist=0.01, metric='cosine')\n",
    "# reducer = umap.UMAP(random_state=2, n_components=2, n_neighbors=3, min_dist=0.01, metric='hellinger')\n",
    "\n",
    "embedding = reducer.fit_transform(doc_term_matrix)\n",
    "embedding = align_points_to_grid(embedding)\n",
    "# embedding = (embedding - np.min(embedding))/np.ptp(embedding) # Normalize 0:1\n",
    "embedding = np.multiply(embedding, 100) # Multiply 100\n",
    "embedding = embedding.astype(int) # Int\n",
    "\n",
    "# Normalize image to between 0 and 255\n",
    "# embedding *= (255.0/image.max())\n",
    "\n",
    "embedding = np.flip(embedding, axis=None) # Optional flip for x and y\n",
    "\n",
    "x = embedding[:, 0]; y = embedding[:, 1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=50)\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.axis('equal')\n",
    "\n",
    "# for i, title in enumerate(titles):\n",
    "#     text = plt.annotate(title, (x[i], y[i]))\n",
    "#     text.set_fontsize(5)\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmas Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 lexical pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[662.0, 661.5, []]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while len(pairs) == 0:\n",
    "    i += .05\n",
    "    \n",
    "    for indexA, a in enumerate(embedding):\n",
    "        for indexB, b in enumerate(embedding):\n",
    "            if indexB > indexA:\n",
    "                distance = dist = math.sqrt((b[0] - a[0])**2 + (b[1] - a[1])**2)\n",
    "                if 0 < distance and distance < i:\n",
    "                    x = (b[0] + a[0]) / 2\n",
    "                    y = (b[1] + a[1]) / 2\n",
    "                    \n",
    "                    intersection = list(set(lemmas[indexA]) & set(lemmas[indexB]))\n",
    "\n",
    "                    wordfreq = []\n",
    "                    for lemma in intersection:\n",
    "                        wordfreq.append([lemma, lemmas[indexA].count(lemma) + lemmas[indexA].count(lemma)])\n",
    "                    \n",
    "                    wordfreq.sort(key=lambda x:x[1])\n",
    "                    wordfreq.reverse()\n",
    "\n",
    "                    pairs.append([x,y, [i[0] for i in wordfreq[:3]] ])\n",
    "\n",
    "\n",
    "print(len(pairs), 'lexical pairs')\n",
    "pairs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hdbscan\n",
    "\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=4, min_samples=3, cluster_selection_epsilon=.2)\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=4, cluster_selection_method='leaf')\n",
    "# min_samples is to consier all the elements that owtherwide will be classified as noise\n",
    "# cluster_selection_epsilon extends clusters\n",
    "clusterer.fit(embedding)\n",
    "clusters = clusterer.labels_\n",
    "\n",
    "# Grouping by cluster\n",
    "\n",
    "values = set(clusters)\n",
    "if -1 in values: values.remove(-1)\n",
    "\n",
    "clusters = [[index for index, cluster in enumerate(clusters) if cluster==value] for value in values]\n",
    "\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(embedding.tolist(), codecs.open('../src/data/embedding.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "# json.dump(authors, codecs.open('../src/data/authors.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "json.dump(lemmas, codecs.open('../src/data/lemmas.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "json.dump(pairs, codecs.open('../src/data/pairs.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "# json.dump(topics, codecs.open('../src/data/topics.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)\n",
    "json.dump(clusters, codecs.open('../src/data/clusters.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 - 1 2 - 2 2 - 3 1 - 4 2 - "
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, get_single_color_func\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# from planar import Polygon # It's not working anymore\n",
    "\n",
    "from os import path\n",
    "import multidict as multidict\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "for index, cluster in enumerate(clusters):\n",
    "\n",
    "    # Preprocessing\n",
    "\n",
    "    scale = 4\n",
    "    \n",
    "    min_X = min([i[0] for i in embedding[cluster]]) * scale\n",
    "    max_X = max([i[0] for i in embedding[cluster]]) * scale\n",
    "    min_Y = min([i[1] for i in embedding[cluster]]) * scale\n",
    "    max_Y = max([i[1] for i in embedding[cluster]]) * scale\n",
    "\n",
    "    width = max_X - min_X; height = max_Y - min_Y\n",
    "    \n",
    "    points = list(map(lambda i: (i[0] * scale - min_X, i[1] * scale - min_Y), embedding[cluster]))\n",
    "\n",
    "    # Hull\n",
    "\n",
    "    hull = ConvexHull(points)\n",
    "\n",
    "    x_hull = np.append(hull.points[hull.vertices,0], hull.points[hull.vertices,0][0])\n",
    "    y_hull = np.append(hull.points[hull.vertices,1], hull.points[hull.vertices,1][0])\n",
    "    \n",
    "    # Interpolation\n",
    "    \n",
    "    dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "    interp_x, interp_y = interpolate.splev(interp_d, spline)    \n",
    "    interp_points = list(zip(interp_x, interp_y))\n",
    "\n",
    "    # Create mask\n",
    "\n",
    "    img = Image.new(mode = \"RGBA\", size = (width, height), color = (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # draw.polygon(points, fill=(0,0,0))\n",
    "    draw.polygon(interp_points, fill=(0,0,0))\n",
    "    mask = np.array(img)\n",
    "\n",
    "\n",
    "    # Collect text\n",
    "\n",
    "    text = []\n",
    "    for id in cluster:\n",
    "        text = text + lemmas[id]\n",
    "    text = ' '.join(map(str, text))\n",
    "    # text = text.replace('datum', 'data')\n",
    "    # text = text.replace('medium', 'media')\n",
    "\n",
    "    dictionary = multidict.MultiDict()\n",
    "    _dictionary = {}\n",
    "\n",
    "\n",
    "    # Frequency\n",
    "\n",
    "    for _word in text.split(\" \"):\n",
    "        val = _dictionary.get(_word, 0)\n",
    "        _dictionary[_word] = val + 1\n",
    "    for key in _dictionary:\n",
    "        dictionary.add(key, _dictionary[key])\n",
    "\n",
    "\n",
    "    # Wordcloud\n",
    "\n",
    "    max_words = math.ceil(len(dictionary)*.01)\n",
    "\n",
    "\n",
    "    wc = WordCloud(\n",
    "        mode = \"RGBA\",\n",
    "        color_func=lambda *args, **kwargs: (0, 0, 0),\n",
    "        font_path = path.join('Lato-Regular.ttf'),\n",
    "        mask=mask,\n",
    "        \n",
    "        normalize_plurals=False,\n",
    "        prefer_horizontal= 1,\n",
    "        \n",
    "        margin=40,\n",
    "\n",
    "        background_color=None,\n",
    "        # background_color='black',\n",
    "\n",
    "        # max_words=max_words,\n",
    "        \n",
    "        min_font_size= 10,\n",
    "        max_font_size= 100,\n",
    "        # collocation_threshold = 20,\n",
    "        relative_scaling = 0,\n",
    "    )\n",
    "\n",
    "    print(index, max_words, '-', end=' ')\n",
    "    \n",
    "    wc.generate_from_frequencies(dictionary) # generate word cloud\n",
    "    wc.to_file(path.join(\"../src/wordclouds/\" + f\"{index:02}\" + \".png\")) # store to file\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
